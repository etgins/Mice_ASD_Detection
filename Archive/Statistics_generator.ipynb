{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Statistics_generator.ipynb","provenance":[],"authorship_tag":"ABX9TyPuL0KXCefrHjxrjZl0ovL/"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"NM5H6sZgJIf6","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1628923193314,"user_tz":-180,"elapsed":428,"user":{"displayName":"Guy Lavy","photoUrl":"","userId":"17597021433543225927"}},"outputId":"60093b29-0ef9-4293-ce8b-d324a36a9595"},"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","%cd /content/drive/Shareddrives/TEST_RECORDINGS/Final_Project/E:/"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","/content/drive/.shortcut-targets-by-id/1lClKCRILD0AwA0p_iwcizl4ernv3OMRC/Final_Project/E:\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"z_HsDdz2JetD","executionInfo":{"status":"ok","timestamp":1628923197260,"user_tz":-180,"elapsed":3552,"user":{"displayName":"Guy Lavy","photoUrl":"","userId":"17597021433543225927"}}},"source":["import numpy as np\n","import PIL.Image as Image\n","import matplotlib.pyplot as plt\n","import tensorflow as tf\n","from tensorflow import keras\n","import tensorflow_hub as hub\n","from tensorflow.keras.preprocessing import image\n","import pandas as pd\n","import os\n","import xlrd\n","import math\n","import scipy\n","import scipy.io.wavfile as wavfile\n","from scipy.signal import butter, lfilter, freqz\n","import librosa\n","import librosa.display\n","import cv2"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"JOO7o_Y7bsNO","executionInfo":{"status":"ok","timestamp":1628923197262,"user_tz":-180,"elapsed":10,"user":{"displayName":"Guy Lavy","photoUrl":"","userId":"17597021433543225927"}}},"source":["def butter_highpass_filter(cutoff_H, fs, order):\n","  nyq = 0.5*fs\n","  normal_cutoff = cutoff_H/nyq\n","  b, a = butter(order, normal_cutoff, btype='high', analog=False)\n","  return a, b\n","\n","class sample:\n","  def __init__(self, mother, name, sex, age, matgen, pupgen, rec_num, syls, time_between):\n","    self.mother = mother\n","    self.name = name\n","    self.sex = sex\n","    self.age = age\n","    self.matgen = matgen\n","    self.pupgen = pupgen\n","    self.rec_num = rec_num\n","    self.syls = syls\n","    self.time_between = time_between"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"I9TtpXXxJN9K","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1628923301809,"user_tz":-180,"elapsed":104555,"user":{"displayName":"Guy Lavy","photoUrl":"","userId":"17597021433543225927"}},"outputId":"aa32af67-865e-42ba-e88b-f7719c2dedb8"},"source":["model_path = '/content/drive/Shareddrives/TEST_RECORDINGS/Final_Project/E:/model_weights.h5'\n","model = keras.models.load_model(model_path, custom_objects={'KerasLayer':hub.KerasLayer})\n","\n","fs = 250000\n","order = 6\n","cutoff_H = 30*10**3\n","c, d = butter_highpass_filter(cutoff_H, fs, order)\n","\n","%cd /content/drive/Shareddrives/TEST_RECORDINGS/Final_Project/Recordings_ella_ayelet/\n","data_table = xlrd.open_workbook('Total_Data.xlsx').sheet_by_index(0)\n","age = data_table.col_values(0, 1)\n","matgen = data_table.col_values(3, 1)\n","pupgen = data_table.col_values(5, 1)\n","mother = data_table.col_values(2, 1)\n","name = data_table.col_values(4, 1)\n","sex = data_table.col_values(16, 1)\n","#syllable = data_table.col_values(14, 1)\n","rec_num = data_table.col_values(6, 1)\n","start = data_table.col_values(7, 1)\n","finish = data_table.col_values(9, 1)"],"execution_count":4,"outputs":[{"output_type":"stream","text":["/content/drive/.shortcut-targets-by-id/1lClKCRILD0AwA0p_iwcizl4ernv3OMRC/Final_Project/Recordings_ella_ayelet\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"RFcti5PvNOG_","executionInfo":{"status":"ok","timestamp":1628925566421,"user_tz":-180,"elapsed":2264621,"user":{"displayName":"Guy Lavy","photoUrl":"","userId":"17597021433543225927"}}},"source":["samples = []\n","sr = 250000\n","max_time = 0.25\n","pred = []\n","timeB = []\n","time_diff = []\n","start_arr = np.array(start) #converting to array\n","finish_arr = np.array(finish)\n","time_diff = np.subtract(finish_arr, start_arr) #calculating each syllable length\n","for i in range(len(mother)):\n","  path = '/content/drive/Shareddrives/TEST_RECORDINGS/Final_Project/Recordings_ella_ayelet/total_data/{}/{}/{}.wav'.format(mother[i], name[i], rec_num[i]) #find path of each recording\n","  if not os.path.exists('{}'.format(path)):\n","    path = '/content/drive/Shareddrives/TEST_RECORDINGS/Final_Project/Recordings_ella_ayelet/total_data/{}/{}/{}.WAV'.format(mother[i], name[i], rec_num[i])\n","    if not os.path.exists('{}'.format(path)):\n","      continue\n","  if i>0 and (rec_num[i] != rec_num[i-1] or name[i] != name[i-1]):\n","    recording = sample(mother[i-1], name[i-1], sex[i-1], age[i-1], matgen[i-1], pupgen[i-1], rec_num[i-1], pred, timeB)\n","    samples.append(recording)\n","    pred = []\n","    timeB = []\n","  if time_diff[i] < max_time:\n","    rec, rate = librosa.load(path, sr) #opens recordings and sample rate, add sample rate of USVs\n","    temp = (max_time - time_diff[i])/2\n","    silence = np.zeros(round((temp)*rate))\n","    trimmed = rec[round((start[i])*rate):round((finish[i])*rate)] #trimming the syllables according to start and fin poitns from excel\n","    syl = np.append(silence, trimmed) #normalizing length to max syllable\n","    syl = np.append(syl, silence)\n","  else:\n","    rec, rate = librosa.load(path, sr)\n","    syl = rec[round((start[i])*rate):round((finish[i])*rate)]\n","  #pre processing\n","  syl = lfilter(d, c, syl) #hpf\n","  #STFT creation\n","  D = np.abs(librosa.stft(syl, n_fft=2048, hop_length=128, win_length=512, window='hamming')) #creating stft and using absolute value for spectrogram\n","  D = cv2.resize(D, dsize=(128, 128), interpolation=cv2.INTER_CUBIC) #resizing the spectograms for usage in the model. INTER_CUBIC – a bicubic interpolation over 4×4 pixel neighborhood\n","  D = D - 0.02*np.mean(D)\n","  D = np.repeat(D[:, :, np.newaxis], 3, -1)\n","  D = D.astype('float32')\n","  D = D/255\n","  D = image.img_to_array(D)\n","  D = np.expand_dims(D, axis=0)\n","  predict = model.predict(D)\n","  pred.append(predict)\n","  if len(pred) > 1:\n","    timeB.append(start[i] - finish[i-1])"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cgXQUsSwNJyU","executionInfo":{"status":"ok","timestamp":1628925666717,"user_tz":-180,"elapsed":347,"user":{"displayName":"Guy Lavy","photoUrl":"","userId":"17597021433543225927"}},"outputId":"bea30535-4aa3-44fd-c2fe-6a289f3f3e54"},"source":["print(samples[201].syls)"],"execution_count":16,"outputs":[{"output_type":"stream","text":["[array([[6.5963695e-07, 9.9983573e-01, 5.5295973e-06, 1.5158570e-04,\n","        1.9157994e-07, 1.8644458e-07, 1.4332860e-06, 1.4128754e-07,\n","        4.3442060e-06, 9.0795069e-08]], dtype=float32), array([[4.8895854e-06, 9.9969101e-01, 8.2325707e-05, 1.7361779e-04,\n","        1.1212920e-06, 1.2539889e-06, 9.0318463e-06, 1.1492280e-06,\n","        3.4971610e-05, 5.0977519e-07]], dtype=float32), array([[4.6518422e-04, 5.3139621e-01, 1.0993157e-03, 4.6582022e-01,\n","        1.0849748e-04, 1.6004439e-04, 1.6301371e-04, 6.9817543e-05,\n","        6.6823821e-04, 4.9581806e-05]], dtype=float32), array([[0.0864318 , 0.00494287, 0.03838528, 0.01559798, 0.00808663,\n","        0.18726593, 0.00310314, 0.01699061, 0.6282043 , 0.01099145]],\n","      dtype=float32)]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"8sR15xeE6H1X","executionInfo":{"status":"ok","timestamp":1628925566429,"user_tz":-180,"elapsed":64,"user":{"displayName":"Guy Lavy","photoUrl":"","userId":"17597021433543225927"}}},"source":["samples = np.array(samples)\n","np.save('model_prediction_recordings' ,samples)"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":148},"id":"uEFjRXfoOmJd","executionInfo":{"status":"ok","timestamp":1628925566434,"user_tz":-180,"elapsed":65,"user":{"displayName":"Guy Lavy","photoUrl":"","userId":"17597021433543225927"}},"outputId":"0acf9fbe-5960-4cfe-cecd-09ea6e56bb9c"},"source":["'''\n","i = 731\n","pred = []\n","timeB = 1\n","sr = 250000 \n","time_diff = []\n","start_arr = np.array(start) #converting to array\n","finish_arr = np.array(finish)\n","time_diff = np.subtract(finish_arr, start_arr)\n","max_time = 0.25\n","path = '/content/drive/Shareddrives/TEST_RECORDINGS/Final_Project/Recordings_ella_ayelet/total_data/{}/{}/{}.wav'.format(mother[i], name[i], rec_num[i])\n","if time_diff[i] < max_time:\n","  rec, rate = librosa.load(path, sr) #opens recordings and sample rate, add sample rate of USVs\n","  temp = (max_time - time_diff[i])/2\n","  silence = np.zeros(round((temp)*rate))\n","  trimmed = rec[round((start[i])*rate):round((finish[i])*rate)] #trimming the syllables according to start and fin poitns from excel\n","  syl = np.append(silence, trimmed) #normalizing length to max syllable\n","  syl = np.append(syl, silence)\n","else:\n","  rec, rate = librosa.load(path, sr)\n","  syl = rec[round((start[i])*rate):round((finish[i])*rate)]\n","#pre processing\n","syl = lfilter(d, c, syl) #hpf\n","\n","D = np.abs(librosa.stft(syl, n_fft=2048, hop_length=128, win_length=512, window='hamming')) #creating stft and using absolute value for spectrogram\n","D = cv2.resize(D, dsize=(128, 128), interpolation=cv2.INTER_CUBIC) #resizing the spectograms for usage in the model. INTER_CUBIC – a bicubic interpolation over 4×4 pixel neighborhood\n","D = D - 0.02*np.mean(D)\n","fig, ax = plt.subplots(nrows=1, ncols=1)\n","ax.pcolormesh(20*np.log10(D))\n","D = np.repeat(D[:, :, np.newaxis], 3, -1)\n","D = D.astype('float32')\n","D = D/255\n","D = image.img_to_array(D)\n","D = np.expand_dims(D, axis=0)\n","predict = model.predict(D)\n","pred.append(predict)\n","pred.append(predict)\n","sample1 = sample(mother[i], name[i], sex[i], age[i], matgen[i], pupgen[i], rec_num[i], pred, timeB)\n","#pred = np.where(pred == np.max(pred))\n","print(sample1.syls)\n","'''"],"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["\"\\ni = 731\\npred = []\\ntimeB = 1\\nsr = 250000 \\ntime_diff = []\\nstart_arr = np.array(start) #converting to array\\nfinish_arr = np.array(finish)\\ntime_diff = np.subtract(finish_arr, start_arr)\\nmax_time = 0.25\\npath = '/content/drive/Shareddrives/TEST_RECORDINGS/Final_Project/Recordings_ella_ayelet/total_data/{}/{}/{}.wav'.format(mother[i], name[i], rec_num[i])\\nif time_diff[i] < max_time:\\n  rec, rate = librosa.load(path, sr) #opens recordings and sample rate, add sample rate of USVs\\n  temp = (max_time - time_diff[i])/2\\n  silence = np.zeros(round((temp)*rate))\\n  trimmed = rec[round((start[i])*rate):round((finish[i])*rate)] #trimming the syllables according to start and fin poitns from excel\\n  syl = np.append(silence, trimmed) #normalizing length to max syllable\\n  syl = np.append(syl, silence)\\nelse:\\n  rec, rate = librosa.load(path, sr)\\n  syl = rec[round((start[i])*rate):round((finish[i])*rate)]\\n#pre processing\\nsyl = lfilter(d, c, syl) #hpf\\n\\nD = np.abs(librosa.stft(syl, n_fft=2048, hop_length=128, win_length=512, window='hamming')) #creating stft and using absolute value for spectrogram\\nD = cv2.resize(D, dsize=(128, 128), interpolation=cv2.INTER_CUBIC) #resizing the spectograms for usage in the model. INTER_CUBIC – a bicubic interpolation over 4×4 pixel neighborhood\\nD = D - 0.02*np.mean(D)\\nfig, ax = plt.subplots(nrows=1, ncols=1)\\nax.pcolormesh(20*np.log10(D))\\nD = np.repeat(D[:, :, np.newaxis], 3, -1)\\nD = D.astype('float32')\\nD = D/255\\nD = image.img_to_array(D)\\nD = np.expand_dims(D, axis=0)\\npredict = model.predict(D)\\npred.append(predict)\\npred.append(predict)\\nsample1 = sample(mother[i], name[i], sex[i], age[i], matgen[i], pupgen[i], rec_num[i], pred, timeB)\\n#pred = np.where(pred == np.max(pred))\\nprint(sample1.syls)\\n\""]},"metadata":{"tags":[]},"execution_count":8}]}]}
