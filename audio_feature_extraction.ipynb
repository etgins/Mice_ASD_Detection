{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "audio_feature_extraction.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "KFdbUJtbzlWS"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/etgins/Mice_ASD_Detection/blob/main/audio_feature_extraction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3YA25Z9BUZPM"
      },
      "source": [
        "----------------------------------------------\n",
        "Written by Itamar Ginsberg & Alon Schreuer, October 2021\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T4POWW7dSKd9"
      },
      "source": [
        "# **1. Import data and split labels**\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZGRoMFfM9O1p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eefff625-1c7d-453e-cc77-219abb77c903"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "## COLAB WORK\n",
        "## ITAMAR:\n",
        "dataset = pd.read_excel('/content/drive/MyDrive/Project_A/Project_A_files/total_data UPDATED EM 020821.xlsx')\n",
        "## ALON:\n",
        "# dataset = pd.read_csv(\"/content/drive/MyDrive/total_data.csv\")\n",
        "## ITAMAR:\n",
        "#dataset.to_csv (r'/content/drive/MyDrive/Project_A/Project_A_files/total_data UPDATED EM 020821.csv', index = None, header=True)\n",
        "# dataset.dropna(axis = 0, how='any')\n",
        "\n",
        "## ALON:\n",
        "#dataset.to_csv(\"/content/drive/MyDrive/total_data.csv\", index = None, header=True)\n",
        "#dataset = pd.read_csv(\"/content/drive/MyDrive/total_data.csv\", error_bad_lines=False)\n",
        "\n",
        "# extract only the relevant columns / features\n",
        "X = dataset[[\"Name\", \"Start Point (Hz)\", \"End Point (Hz)\", \"Duration (s)\", \"Syllable number\", \"Offspring Genotype\"]]\n",
        "# clean NaN values from dataset or X\n",
        "X = X.dropna(axis = 0, how='any')\n",
        "# print(X)\n",
        "\n",
        "# create labels\n",
        "y = X[[\"Offspring Genotype\"]]\n",
        "print(y)\n",
        "# encode labels\n",
        "l1 = LabelEncoder()\n",
        "l1.fit(y)\n",
        "y = l1.transform(y)\n",
        "X[[\"Offspring Genotype\"]] = y\n",
        "print(X)\n",
        "# OR use this:\n",
        "      # convert the target column to categorical\n",
        "      # col = pd.Categorical(y)\n",
        "      # y = pd.Series(col.codes)\n",
        "\n",
        "\n",
        "\n",
        "# convert duration to micro-seconds from 'datetime.time' type to 'timedelta' object\n",
        "from datetime import datetime\n",
        "duration_vec = X[[\"Duration (s)\"]]\n",
        "# print(duration_vec)\n",
        "duration_vec2 = np.array(duration_vec)\n",
        "# print(duration_vec2)\n",
        "duration_vec3 = np.zeros([1, np.size(duration_vec2)])\n",
        "# print(duration_vec3)\n",
        "for i in range (len(duration_vec)):\n",
        "  duration_single = duration_vec2[i,0]\n",
        "  # print(duration_single)\n",
        "  duration_vec3[0,i] = int(duration_single.strftime(format = '%f'))\n",
        "  # print(duration_vec3[0,i])\n",
        "X[[\"Duration (s)\"]] = np.transpose(duration_vec3)\n",
        "# print(X)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# X.describe()"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "     Offspring Genotype\n",
            "1                    WT\n",
            "2                    WT\n",
            "3                    WT\n",
            "4                    WT\n",
            "5                    WT\n",
            "...                 ...\n",
            "3167                 WT\n",
            "3170                 HT\n",
            "3171                 HT\n",
            "3172                 HT\n",
            "3173                 HT\n",
            "\n",
            "[3035 rows x 1 columns]\n",
            "        Name  Start Point (Hz)  ...  Syllable number Offspring Genotype\n",
            "1     17470O        57648.8278  ...              3.0                  1\n",
            "2     17470O        55558.5268  ...              2.0                  1\n",
            "3     17470O        54513.3763  ...              2.0                  1\n",
            "4     17470O        55976.5870  ...              2.0                  1\n",
            "5     17470O        59739.1288  ...              4.0                  1\n",
            "...      ...               ...  ...              ...                ...\n",
            "3167  08121P        73793.2416  ...              8.0                  1\n",
            "3170  08130I        65382.9415  ...              8.0                  0\n",
            "3171  08130I        68936.4532  ...              1.0                  0\n",
            "3172  08130I        82105.3495  ...              8.0                  0\n",
            "3173  08130I        77297.6572  ...              2.0                  0\n",
            "\n",
            "[3035 rows x 6 columns]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hz5Ehn_USzN5"
      },
      "source": [
        "# **2. Split data for different mice by name - unfinished**\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7nw3zPiKFS3M"
      },
      "source": [
        "# split dataset for each mouse\n",
        "\n",
        "def take_data_by_name(name_searched, Data, name_list):\n",
        "  # print(name_list)\n",
        "  ind = name_list == name_searched\n",
        "  # print(ind)\n",
        "  matching_data = Data[ind].reset_index()\n",
        "  # TODO - drop index column\n",
        "  \n",
        "  # print(matching_data)\n",
        "  return matching_data\n",
        "\n",
        "\n",
        "# find set of mouse names\n",
        "name_column = X[\"Name\"]\n",
        "unique_name_set = set(name_column)\n",
        "unique_name_list = list(unique_name_set)\n",
        "# unique_name_list = unique_name_list[0:-1]   # first entry is column name\n",
        "\n",
        "number_of_mice = len(unique_name_list)\n",
        "# print(unique_name_list)\n",
        "# print(number_of_mice, 'mice in data')\n",
        "\n",
        "# remove nan from list of names\n",
        "unique_name_list = [x for x in unique_name_list if str(x) != 'nan']\n",
        "number_of_mice = len(unique_name_list)\n",
        "\n",
        "# print(unique_name_list)\n",
        "# print(number_of_mice, 'mice in data')"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6eQ4bDtlTEnT"
      },
      "source": [
        "# **3. Extract features**\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "holjmiWRS-RF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "31de322d-0fe5-4522-d3fe-342e985863b0"
      },
      "source": [
        "  # final data is made up of: \n",
        "    # avg. start freq. per syllable\n",
        "    # avg. end freq. per syllable\n",
        "    # avg. syllable duration per syllable\n",
        "    # syllable distribution - percentage of each syllable\n",
        "    # Bandwidth - TBD\n",
        "\n",
        "num_of_syllables = 10\n",
        "final_data_size = 4*num_of_syllables\n",
        "# initialize finalized data variable: mouse_final_data\n",
        "mouse_final_data = np.zeros([number_of_mice,final_data_size+1]) # the extra column will hold the genotype label\n",
        "\n",
        "\"\"\" \n",
        "Work on each mouse separately and calculate all features.\n",
        "Place the results in mouse_final_data[mouse_idx,:]\n",
        "\"\"\"\n",
        "\n",
        "for idx in range (0,number_of_mice): \n",
        "    mouse_split_data = take_data_by_name(unique_name_list[idx], X, name_column)\n",
        "    # print('mouse name:', unique_name_list[idx],', ' 'idx:', idx)\n",
        "    # print('matching data:', '\\n',mouse_split_data)\n",
        "\n",
        "\n",
        "\n",
        "    # calculate feature 1 - average start freq for each syllable (Alon)\n",
        "    ## -------------------------------------------\n",
        "    # print(\"\\n\", \"--- CALCULATING FEATURE 1: average start freq for each syllable ---\", \"\\n\")\n",
        "    \"\"\"\n",
        "    - take start frequencies grouped by syllable number, and calculate the average\n",
        "    - fill a 10-long vector with the final result ( = add zeros to non-existing syllables)\n",
        "    - place in mouse_final_data[0:10]\n",
        "    \"\"\"\n",
        "\n",
        "    start_frequencies = np.array(mouse_split_data.groupby(by = 'Syllable number', as_index=False)[\"Start Point (Hz)\"].mean())\n",
        "    # print('start_frequencies :','\\n',start_frequencies,'\\n')\n",
        "    \n",
        "    feature1_vec = np.zeros([1,10])\n",
        "    for i in range(len(start_frequencies)):\n",
        "      feature1_vec[0,int(start_frequencies[i,0])-1] = start_frequencies[i,1]\n",
        "    \n",
        "    # PRINT RESULT:\n",
        "    # print('each syllable mean start freq:','\\n', feature1_vec, '\\n')\n",
        "\n",
        "\n",
        "    mouse_final_data[idx,0:10] = feature1_vec\n",
        "\n",
        "\n",
        "    # calculate feature 2 - average end freq for each syllable (Alon)\n",
        "    ## -------------------------------------------\n",
        "    # print(\"\\n\", \"--- CALCULATING FEATURE 2: average end freq for each syllable ---\", \"\\n\")\n",
        "    \n",
        "\n",
        "    \"\"\"\n",
        "    ITAMAR:\n",
        "    - take end frequencies grouped by syllable number, and calculate the average\n",
        "    - fill a 10-long vector with the final result ( = add zeros to non-existing syllables)\n",
        "    - place in mouse_final_data[0:10]\n",
        "    \"\"\"\n",
        "\n",
        "    end_frequencies = np.array(mouse_split_data.groupby(by = 'Syllable number', as_index=False)[\"End Point (Hz)\"].mean())\n",
        "    # print('end_frequencies :','\\n',end_frequencies, '\\n')\n",
        "    \n",
        "    feature2_vec = np.zeros([1,10])\n",
        "    for i in range(len(end_frequencies)):\n",
        "      feature2_vec[0,int(end_frequencies[i,0])-1] = end_frequencies[i,1]\n",
        "    \n",
        "    # PRINT RESULT:\n",
        "    # print('each syllable mean end freq:','\\n', feature2_vec, '\\n')\n",
        "\n",
        "    mouse_final_data[idx,10:20] = feature2_vec\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    ## -------------------------------------------\n",
        "    # calculate feature 3 - syllable distribution (Itamar):\n",
        "    ## -------------------------------------------\n",
        "    # print(\"\\n\", \"--- CALCULATING FEATURE 3: mouse's syllable distribution ---\", \"\\n\")\n",
        "\n",
        "  # take syll numbers\n",
        "    syllable_num_row = np.transpose(np.array(mouse_split_data[\"Syllable number\"]))\n",
        "    # print(syllable_num_row)\n",
        "\n",
        "  # initialize distribution vector\n",
        "    distribution = np.zeros([1,10])\n",
        "    # print(distribution)\n",
        "\n",
        "  # increment syllable count\n",
        "    for i in range(len(syllable_num_row)):\n",
        "      # print(\"iteration\", i)\n",
        "      syll = int(syllable_num_row[i])\n",
        "      # print(\"found syllable\", syll)\n",
        "      # print(\"old distribution:\", distribution)\n",
        "      distribution[0,syll-1] += 1 \n",
        "      # print(\"new distribution:\", distribution)\n",
        "\n",
        "  # normalize histogram to distribution\n",
        "    distribution = distribution / distribution.sum()\n",
        "    # if all are zeros, dividing by zero will create nan's - make them zero\n",
        "    distribution[np.isnan(distribution)] = 0  \n",
        "\n",
        "    # PRINT RESULT:\n",
        "    # print(\"final distribution:\", \"\\n\", distribution)\n",
        "\n",
        "  # transfer results to mouse_final_data\n",
        "    mouse_final_data[idx,20:30] = distribution\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    ## -------------------------------------------\n",
        "    # calculate feature 4 - average syllable duration for each syllable (Itamar)\n",
        "    ## -------------------------------------------\n",
        "    # print(\"\\n\", \"--- CALCULATING FEATURE 4: average syllable duration for each syllable ---\", \"\\n\")\n",
        "    \n",
        "    # take the mean of the duration column for each syllable\n",
        "    mouse_duration = mouse_split_data[[\"Name\", \"Syllable number\",\"Duration (s)\"]]\n",
        "    # print(mouse_duration)\n",
        "    a = mouse_duration.groupby('Syllable number', as_index=False)[\"Duration (s)\"].mean()\n",
        "    a = np.array(a)\n",
        "    \n",
        "    # PRINT RESULT:\n",
        "    # print(\"for this mouse, each syllable's mean duration is:\",\"\\n\", a)\n",
        "\n",
        "    feature4_vec = np.zeros([1,10])\n",
        "    # print(np.shape(a))\n",
        "    for i in range (len(a)):\n",
        "      # print('iteration ', i)\n",
        "      # print(int(a[i,0]))\n",
        "      syllable = int(a[i,0])\n",
        "      feature4_vec[0,syllable-1] = int(a[i,1])\n",
        "      # print(\" means_vec:\", means_vec)\n",
        "    \n",
        "    mouse_final_data[idx,30:40] = feature4_vec\n",
        "\n",
        "\n",
        "\n",
        "    ## -------------------------------------------\n",
        "    # calculate feature 5 - Bandwidth (???) - TBD\n",
        "    ## -------------------------------------------\n",
        "    # print(\"\\n\", \"--- CALCULATING FEATURE 5: Bandwidth ---\", \"\\n\")\n",
        "\n",
        "\n",
        "\n",
        "    ## -------------------------------------------\n",
        "    # find mouse's label\n",
        "    ## -------------------------------------------\n",
        "    mouse_final_data[idx,-1] = mouse_split_data[\"Offspring Genotype\"].iloc[0]\n",
        "\n",
        "\n",
        "    # print(\"\\n\", \"--- FINISHED features, show final data: --- (mouse \", idx, \")\" \"\\n\")\n",
        "    # print(mouse_final_data[idx,:], \"\\n\")\n",
        "\n",
        "\n",
        "print(\"\\n\", \"--- FINAL DATA FOR ALL MICE --- \", \"\\n\")\n",
        "print(mouse_final_data[:,:], \"\\n\")\n",
        "\n",
        "\n",
        "np.savetxt(\"processed_data_for_final_classification.csv\", X=mouse_final_data, delimiter=\",\")\n",
        "# np.save(\"trial2.csv\",mouse_final_data)\n",
        "!cp \"processed_data_for_final_classification.csv\" /content/drive/MyDrive/Project_A/Project_A_files\n"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " --- FINAL DATA FOR ALL MICE ---  \n",
            "\n",
            "[[6.94129079e+04 5.80254787e+04 6.34544756e+04 ... 0.00000000e+00\n",
            "  0.00000000e+00 1.00000000e+00]\n",
            " [8.54836700e+04 0.00000000e+00 8.48825299e+04 ... 6.87280000e+04\n",
            "  0.00000000e+00 1.00000000e+00]\n",
            " [6.83624883e+04 6.08928857e+04 6.14381733e+04 ... 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00]\n",
            " ...\n",
            " [9.95941393e+04 7.10685975e+04 6.22200727e+04 ... 7.57500000e+04\n",
            "  0.00000000e+00 1.00000000e+00]\n",
            " [7.75763640e+04 7.65755532e+04 7.68198741e+04 ... 6.67500000e+04\n",
            "  0.00000000e+00 1.00000000e+00]\n",
            " [0.00000000e+00 4.99147141e+04 7.30473785e+04 ... 6.28330000e+04\n",
            "  7.80000000e+04 1.00000000e+00]] \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KFdbUJtbzlWS"
      },
      "source": [
        "Archive\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g6tnKDT8zkGt"
      },
      "source": [
        "  \"\"\" ALON OLD CODE\n",
        "  # TODO \n",
        "  # extract all syllables per mouse - done\n",
        "  # create a dictionay with num of syllable as key and all it's start freqs arrange in list as a value\n",
        "  # for every value in the dictionary compute the average\n",
        "  # to it again in a loop for every mouse such that in the end I'll get an array with num of mouse as a key and the value is the dictionay with the average of start freqs per syllable (*think about better way to arrange the data)\n",
        "  \n",
        "\n",
        "  # create a dictionay with num of syllable as key and the sum of it's start freqs \n",
        "  # dict = {}\n",
        "  # start_freq = np.array(mouse_split_data[\"Start Point (Hz)\"]) # array of start_freqs\n",
        "  # syllable_num = np.array(mouse_split_data[\"Syllable number\"]) # array of sillable num\n",
        "  # start_freq_check_nan = [~np.isnan(start_freq)] # start_freqs array convert to in_nan (true/false)\n",
        "  # count = 0\n",
        "  # for i in syllable_num:\n",
        "  #   j = [~np.isnan(i)]\n",
        "  #   if not j:\n",
        "  #     print(\"alon\")\n",
        "  #     continue\n",
        "  #   else:\n",
        "  #     dict[i] = dict[i] + start_freq[i]\n",
        "  # print(dict)\n",
        "  \n",
        "# print(start_freq)\n",
        "# print(len(start_freq))\n",
        "    # get the num of each syllable \n",
        "\n",
        "  \"\"\""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}