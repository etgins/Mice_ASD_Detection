{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "audio_feature_extraction.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/etgins/Mice_ASD_Detection/blob/main/audio_feature_extraction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3YA25Z9BUZPM"
      },
      "source": [
        "----------------------------------------------\n",
        "Written by Itamar Ginsberg & Alon Schreuer, October 2021\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T4POWW7dSKd9"
      },
      "source": [
        "# **1. Import data and split labels**\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZGRoMFfM9O1p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4f72314-97e2-4c5d-bf65-3d42fedbe925"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "# import dataset from xls\n",
        "import pandas as pd\n",
        "\n",
        "## COLAB WORK\n",
        "## ITAMAR:\n",
        "dataset = pd.read_excel('/content/drive/MyDrive/Project_A/Project_A_files/total_data UPDATED EM 020821.xlsx')\n",
        "## ALON:\n",
        "# dataset = pd.read_csv(\"/content/drive/MyDrive/total_data.csv\")\n",
        "## ITAMAR:\n",
        "#dataset.to_csv (r'/content/drive/MyDrive/Project_A/Project_A_files/total_data UPDATED EM 020821.csv', index = None, header=True)\n",
        "# dataset.dropna(axis = 0, how='any')\n",
        "\n",
        "## ALON:\n",
        "#dataset.to_csv(\"/content/drive/MyDrive/total_data.csv\", index = None, header=True)\n",
        "#dataset = pd.read_csv(\"/content/drive/MyDrive/total_data.csv\", error_bad_lines=False)\n",
        "\n",
        "# extract only the relevant columns / features\n",
        "X = dataset[[\"Name\", \"Start Point (Hz)\", \"End Point (Hz)\", \"Duration (s)\", \"Syllable number\"]]\n",
        "y = dataset[[\"Offspring Genotype\"]]\n",
        "\n",
        "# TODO - clean NaN values from dataset or X\n",
        "X2 = X.dropna(axis = 0, how='any')\n",
        "print(X2)\n",
        "\n",
        "# HELP - convert duration to seconds from 'datetime.time' type to 'timedelta' object\n",
        "\n",
        "\n",
        "## TODO - encode text feature values\n",
        "# from sklearn.preprocessing import LabelEncoder\n",
        "# l1 = LabelEncoder()\n",
        "# l1.fit(X['Name'])\n",
        "# dataset.Name = l1.transform(dataset.Name)\n",
        "# dataset\n",
        "\n",
        "# X.describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "        Name  Start Point (Hz)  ...     Duration (s) Syllable number\n",
            "1     17470O        57648.8278  ...  00:00:00.059000             3.0\n",
            "2     17470O        55558.5268  ...  00:00:00.063000             2.0\n",
            "3     17470O        54513.3763  ...  00:00:00.063000             2.0\n",
            "4     17470O        55976.5870  ...  00:00:00.060000             2.0\n",
            "5     17470O        59739.1288  ...  00:00:00.076000             4.0\n",
            "...      ...               ...  ...              ...             ...\n",
            "3167  08121P        73793.2416  ...  00:00:00.051000             8.0\n",
            "3170  08130I        65382.9415  ...  00:00:00.076000             8.0\n",
            "3171  08130I        68936.4532  ...  00:00:00.034000             1.0\n",
            "3172  08130I        82105.3495  ...  00:00:00.087000             8.0\n",
            "3173  08130I        77297.6572  ...  00:00:00.048000             2.0\n",
            "\n",
            "[3035 rows x 5 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hz5Ehn_USzN5"
      },
      "source": [
        "# **2. Split data for different mice by name - unfinished**\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7nw3zPiKFS3M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5fdda8b7-6ae6-4a4a-fcab-03b1a89c691d"
      },
      "source": [
        "# split dataset for each mouse\n",
        "\n",
        "def take_data_by_name(name_searched, Data, name_list):\n",
        "  # print(name_list)\n",
        "  ind = name_list == name_searched\n",
        "  # print(ind)\n",
        "  matching_data = Data[ind].reset_index()\n",
        "  # TODO - drop index column\n",
        "  \n",
        "  # print(matching_data)\n",
        "  return matching_data\n",
        "\n",
        "\n",
        "# find set of mouse names\n",
        "name_column = dataset[\"Name\"]\n",
        "unique_name_set = set(name_column)\n",
        "unique_name_list = list(unique_name_set)\n",
        "# unique_name_list = unique_name_list[0:-1]   # first entry is column name\n",
        "number_of_mice = len(unique_name_list)\n",
        "print(number_of_mice, 'mice in data')\n",
        "unique_name_list.pop(0)\n",
        "print(unique_name_list)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "51 mice in data\n",
            "['17491K', '17472I', '17471P', '08110N', '08111I', '08139L', '08142K', '08139L(2)', '08130I', '08101L', '17484J', '17482K', '17455J', '17479L ', '17454L', '17490J', '08132N', '08136G', '08060M', '08057P', '08169M', '08109B', '08137B', '08103J', '08096P', '08105P', '17470O', '08134N(2)', '17456K', '17474J', '08113G', '08098I', '17444K', '17489I', '17453I', '17450L', '08056J', '08119O', '08059O', '08102I', '08121P', '08027I', '17477I', '08028L', '08112K', '08104K', '08106M', '08107O', '17479L', '08114J']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6eQ4bDtlTEnT"
      },
      "source": [
        "# **3. Extract features**\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "holjmiWRS-RF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d85487c-95bb-4a60-aaf9-4660583505bd"
      },
      "source": [
        "  # final data is made up of: \n",
        "    # avg. start freq. per syllable\n",
        "    # avg. end freq. per syllable\n",
        "    # avg. syllable duration per syllable\n",
        "    # syllable distribution - percentage of each syllable\n",
        "    # Bandwidth - TODO\n",
        "\n",
        "num_of_syllables = 10\n",
        "final_data_size = 4*num_of_syllables\n",
        "# initialize finalized data variable: mouse_final_data\n",
        "mouse_final_data = np.zeros([number_of_mice,final_data_size])\n",
        "\n",
        "\"\"\" \n",
        "Work on each mouse separately and calculate all features.\n",
        "Place the results in mouse_final_data[mouse_idx]\n",
        "\"\"\"\n",
        "for idx in range (10,11): # TODO - when finished, replace with: (number_of_mice):\n",
        "    mouse_split_data = take_data_by_name(unique_name_list[idx], X2, name_column)\n",
        "    print('mouse name:', unique_name_list[idx],', ' 'idx:', idx)\n",
        "    print('matching data:', '\\n',mouse_split_data)\n",
        "\n",
        "  # calculate feature 1 - average start freq for each syllable (Alon)\n",
        "  ## -------------------------------------------\n",
        "  print(\"\\n\", \"--- CALCULATING FEATURE 1: average start freq for each syllable ---\", \"\\n\")\n",
        "\n",
        "  # TODO \n",
        "  # extract all syllables per mouse - done\n",
        "  # create a dictionay with num of syllable as key and all it's start freqs arrange in list as a value\n",
        "  # for every value in the dictionary compute the average\n",
        "  # to it again in a loop for every mouse such that in the end I'll get an array with num of mouse as a key and the value is the dictionay with the average of start freqs per syllable (*think about better way to arrange the data)\n",
        "  \n",
        "\n",
        "  # create a dictionay with num of syllable as key and the sum of it's start freqs \n",
        "  # dict = {}\n",
        "  # start_freq = np.array(mouse_split_data[\"Start Point (Hz)\"]) # array of start_freqs\n",
        "  # syllable_num = np.array(mouse_split_data[\"Syllable number\"]) # array of sillable num\n",
        "  # start_freq_check_nan = [~np.isnan(start_freq)] # start_freqs array convert to in_nan (true/false)\n",
        "  # count = 0\n",
        "  # for i in syllable_num:\n",
        "  #   j = [~np.isnan(i)]\n",
        "  #   if not j:\n",
        "  #     print(\"alon\")\n",
        "  #     continue\n",
        "  #   else:\n",
        "  #     dict[i] = dict[i] + start_freq[i]\n",
        "  # print(dict)\n",
        "  \n",
        "# print(start_freq)\n",
        "# print(len(start_freq))\n",
        "\n",
        "  \n",
        "  \n",
        "\n",
        "  # get the num of each syllable \n",
        "\n",
        "\n",
        "  # calculate feature 2 - average end freq for each syllable (Alon)\n",
        "  ## -------------------------------------------\n",
        "  print(\"\\n\", \"--- CALCULATING FEATURE 2: average end freq for each syllable ---\", \"\\n\")\n",
        "  a = mouse_split_data.groupby(by = 'Syllable number', as_index=False)[\"End Point (Hz)\"].mean()\n",
        "  print(a)\n",
        "\n",
        "  # calculate feature 3 - syllable distribution (Itamar):\n",
        "  ## -------------------------------------------\n",
        "  print(\"\\n\", \"--- CALCULATING FEATURE 3: mouse's syllable distribution ---\", \"\\n\")\n",
        "# get rid of NaN\n",
        "  mouse_split_data = mouse_split_data.dropna(subset=[\"Syllable number\"])\n",
        "\n",
        "# take syll numbers\n",
        "  syllable_num_row = np.transpose(np.array(mouse_split_data[\"Syllable number\"]))\n",
        "  # print(syllable_num_row)\n",
        "\n",
        "# initialize distribution vector\n",
        "  distribution = np.zeros([1,10])\n",
        "  # print(distribution)\n",
        "\n",
        "# increment syllable count\n",
        "  for i in range(len(syllable_num_row)):\n",
        "    # print(\"iteration\", i)\n",
        "    syll = int(syllable_num_row[i])\n",
        "    # print(\"found syllable\", syll)\n",
        "    # print(\"old distribution:\", distribution)\n",
        "    distribution[0,syll-1] += 1 \n",
        "    # print(\"new distribution:\", distribution)\n",
        "\n",
        "# normalize histogram to distribution\n",
        "  distribution = distribution / distribution.sum()\n",
        "  print(\"final distribution:\", \"\\n\", distribution)\n",
        "\n",
        "# transfer results to mouse_final_data\n",
        "  mouse_final_data[idx,21:31] = distribution\n",
        "\n",
        "\n",
        "  # calculate feature 4 - average syllable duration for each syllable (Alon)\n",
        "  ## -------------------------------------------\n",
        "  print(\"\\n\", \"--- CALCULATING FEATURE 4: average syllable duration for each syllable ---\", \"\\n\")\n",
        "  ## HELP - convert \"Duration (s)\" to seconds\n",
        "  # from datetime import datetime, timedelta\n",
        "  # temp = X[\"Duration (s)\"]\n",
        "  # var = temp[20]\n",
        "  # # var = datetime.today()  \n",
        "  # print(var)\n",
        "  # print(type(var))\n",
        "  # another_temp = var.timestamp()\n",
        "  # print(another_temp)\n",
        "  # print(type(another_temp))\n",
        "  \n",
        "  \n",
        "  # HELP - group by syllable index, then take the mean of the duration column for each syllable\n",
        "  # NOTE - RIGHT NOW MIN AND MAX ARE POSSIBLE\n",
        "  mouse_duration = mouse_split_data[[\"Name\", \"Syllable number\",\"Duration (s)\"]]\n",
        "  a = mouse_duration.groupby('Syllable number', as_index=False)[\"Duration (s)\"].max()\n",
        "  print(\"for this mouse, each syllable's max duration is:\",\"\\n\", a)\n",
        "\n",
        "  \n",
        "  # calculate feature 5 - Bandwidth (???) - TBD\n",
        "  ## -------------------------------------------\n",
        "  print(\"\\n\", \"--- CALCULATING FEATURE 5: Bandwidth ---\", \"\\n\")\n",
        "\n",
        "  print(\"\\n\", \"--- FINISHED features, show final data: ---\", \"\\n\")\n",
        "  print(mouse_final_data[idx,:], \"\\n\")\n",
        "\n",
        "\n",
        "\n",
        "# TODO - choose how to format final data and add label\n",
        "# ---> set up for use with final classification model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mouse name: 17484J , idx: 10\n",
            "matching data: \n",
            "     index    Name  ...     Duration (s)  Syllable number\n",
            "0    2554  17484J  ...  00:00:00.092000              8.0\n",
            "1    2555  17484J  ...  00:00:00.079000              8.0\n",
            "2    2556  17484J  ...  00:00:00.077000              8.0\n",
            "3    2557  17484J  ...  00:00:00.077000              8.0\n",
            "4    2558  17484J  ...  00:00:00.087000              7.0\n",
            "5    2559  17484J  ...  00:00:00.030000              8.0\n",
            "6    2560  17484J  ...  00:00:00.029000              1.0\n",
            "7    2561  17484J  ...  00:00:00.061000              8.0\n",
            "8    2562  17484J  ...  00:00:00.106000              7.0\n",
            "9    2563  17484J  ...  00:00:00.076000              8.0\n",
            "10   2564  17484J  ...  00:00:00.066000              8.0\n",
            "11   2565  17484J  ...  00:00:00.012000              1.0\n",
            "12   2566  17484J  ...  00:00:00.077000              8.0\n",
            "13   2567  17484J  ...  00:00:00.102000              8.0\n",
            "14   2568  17484J  ...  00:00:00.076000              8.0\n",
            "15   2569  17484J  ...  00:00:00.058000              3.0\n",
            "\n",
            "[16 rows x 6 columns]\n",
            "\n",
            " --- CALCULATING FEATURE 1: average start freq for each syllable --- \n",
            "\n",
            "\n",
            " --- CALCULATING FEATURE 2: average end freq for each syllable --- \n",
            "\n",
            "   Syllable number  End Point (Hz)\n",
            "0              1.0    72908.025100\n",
            "1              3.0    76461.536800\n",
            "2              7.0    66950.667250\n",
            "3              8.0    77430.676373\n",
            "\n",
            " --- CALCULATING FEATURE 3: mouse's syllable distribution --- \n",
            "\n",
            "final distribution: \n",
            " [[0.125  0.     0.0625 0.     0.     0.     0.125  0.6875 0.     0.    ]]\n",
            "\n",
            " --- CALCULATING FEATURE 4: average syllable duration for each syllable --- \n",
            "\n",
            "for this mouse, each syllable's max duration is: \n",
            "    Syllable number     Duration (s)\n",
            "0              1.0  00:00:00.029000\n",
            "1              3.0  00:00:00.058000\n",
            "2              7.0  00:00:00.106000\n",
            "3              8.0  00:00:00.102000\n",
            "\n",
            " --- CALCULATING FEATURE 5: Bandwidth --- \n",
            "\n",
            "\n",
            " --- FINISHED features, show final data: --- \n",
            "\n",
            "[0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
            " 0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
            " 0.     0.125  0.     0.0625 0.     0.     0.     0.125  0.6875 0.\n",
            " 0.     0.     0.     0.     0.     0.     0.     0.     0.     0.    ] \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
            "  import sys\n"
          ]
        }
      ]
    }
  ]
}