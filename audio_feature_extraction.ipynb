{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "audio_feature_extraction.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/etgins/Mice_ASD_Detection/blob/main/audio_feature_extraction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3YA25Z9BUZPM"
      },
      "source": [
        "----------------------------------------------\n",
        "Written by Itamar Ginsberg & Alon Schreuer, October 2021\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T4POWW7dSKd9"
      },
      "source": [
        "# **1. Import data and split labels**\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZGRoMFfM9O1p",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 432
        },
        "outputId": "f5f9333b-c3ce-4db9-ba6d-af27a1ee7fe8"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "# import dataset from xls\n",
        "import pandas as pd\n",
        "\n",
        "## COLAB WORK\n",
        "## ITAMAR:\n",
        "dataset = pd.read_excel('/content/drive/MyDrive/Project_A/Project_A_files/total_data UPDATED EM 020821.xlsx')\n",
        "## ALON:\n",
        "# dataset = pd.read_csv(\"/content/drive/MyDrive/total_data.csv\")\n",
        "## ITAMAR:\n",
        "#dataset.to_csv (r'/content/drive/MyDrive/Project_A/Project_A_files/total_data UPDATED EM 020821.csv', index = None, header=True)\n",
        "# dataset.dropna(axis = 0, how='any')\n",
        "\n",
        "## ALON:\n",
        "#dataset.to_csv(\"/content/drive/MyDrive/total_data.csv\", index = None, header=True)\n",
        "#dataset = pd.read_csv(\"/content/drive/MyDrive/total_data.csv\", error_bad_lines=False)\n",
        "\n",
        "# extract only the relevant columns / features\n",
        "X = dataset[[\"Name\", \"Start Point (Hz)\", \"End Point (Hz)\", \"Duration (s)\", \"Syllable number\"]]\n",
        "y = dataset[[\"Offspring Genotype\"]]\n",
        "\n",
        "# TODO - clean NaN values from dataset or X\n",
        "X.dropna(axis = 0, how='any')\n",
        "X\n",
        "\n",
        "# TODO - convert duration to seconds from 'datetime.time' type to 'timedelta' object\n",
        "\n",
        "\n",
        "## TODO - encode text feature values\n",
        "# from sklearn.preprocessing import LabelEncoder\n",
        "# l1 = LabelEncoder()\n",
        "# l1.fit(X['Name'])\n",
        "# dataset.Name = l1.transform(dataset.Name)\n",
        "# dataset\n",
        "\n",
        "# X.describe()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Name</th>\n",
              "      <th>Start Point (Hz)</th>\n",
              "      <th>End Point (Hz)</th>\n",
              "      <th>Duration (s)</th>\n",
              "      <th>Syllable number</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>17470O</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>17470O</td>\n",
              "      <td>57648.8278</td>\n",
              "      <td>45525.0820</td>\n",
              "      <td>00:00:00.059000</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>17470O</td>\n",
              "      <td>55558.5268</td>\n",
              "      <td>45525.0820</td>\n",
              "      <td>00:00:00.063000</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>17470O</td>\n",
              "      <td>54513.3763</td>\n",
              "      <td>43852.8412</td>\n",
              "      <td>00:00:00.063000</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>17470O</td>\n",
              "      <td>55976.5870</td>\n",
              "      <td>43434.7810</td>\n",
              "      <td>00:00:00.060000</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4363</th>\n",
              "      <td>17472I</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>7.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4364</th>\n",
              "      <td>17472I</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>7.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4365</th>\n",
              "      <td>17472I</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>7.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4366</th>\n",
              "      <td>17472I</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4367</th>\n",
              "      <td>17472I</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>7.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4368 rows Ã— 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        Name  Start Point (Hz)  ...     Duration (s) Syllable number\n",
              "0     17470O               NaN  ...              NaN             NaN\n",
              "1     17470O        57648.8278  ...  00:00:00.059000             3.0\n",
              "2     17470O        55558.5268  ...  00:00:00.063000             2.0\n",
              "3     17470O        54513.3763  ...  00:00:00.063000             2.0\n",
              "4     17470O        55976.5870  ...  00:00:00.060000             2.0\n",
              "...      ...               ...  ...              ...             ...\n",
              "4363  17472I               NaN  ...              NaN             7.0\n",
              "4364  17472I               NaN  ...              NaN             7.0\n",
              "4365  17472I               NaN  ...              NaN             7.0\n",
              "4366  17472I               NaN  ...              NaN             1.0\n",
              "4367  17472I               NaN  ...              NaN             7.0\n",
              "\n",
              "[4368 rows x 5 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hz5Ehn_USzN5"
      },
      "source": [
        "# **2. Split data for different mice by name - unfinished**\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7nw3zPiKFS3M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22e3fe57-c404-44a0-e80a-ad988540e04c"
      },
      "source": [
        "# split dataset for each mouse\n",
        "\n",
        "def take_data_by_name(name_searched, Data, name_list):\n",
        "  # print(name_list)\n",
        "  ind = name_list == name_searched\n",
        "  # print(ind)\n",
        "  matching_data = Data[ind]\n",
        "  # print(matching_data)\n",
        "  return matching_data\n",
        "\n",
        "\n",
        "# find set of mouse names\n",
        "name_column = dataset[\"Name\"]\n",
        "unique_name_set = set(name_column)\n",
        "unique_name_list = list(unique_name_set)\n",
        "# unique_name_list = unique_name_list[0:-1]   # first entry is column name\n",
        "number_of_mice = len(unique_name_list)\n",
        "print(number_of_mice, 'mice in data')\n",
        "unique_name_list.pop(0)\n",
        "print(unique_name_list)\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "51 mice in data\n",
            "['08113G', '17477I', '08101L', '08114J', '08028L', '17453I', '17456K', '17474J', '17471P', '08098I', '08134N(2)', '08132N', '08169M', '08056J', '08111I', '08112K', '08059O', '08096P', '17455J', '08130I', '08027I', '08109B', '17489I', '17482K', '08137B', '17479L ', '17450L', '08103J', '08057P', '08136G', '17491K', '08104K', '08139L(2)', '17472I', '17479L', '17484J', '08105P', '08110N', '08060M', '08142K', '08106M', '08107O', '08139L', '17470O', '08121P', '17454L', '17444K', '08119O', '17490J', '08102I']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6eQ4bDtlTEnT"
      },
      "source": [
        "# **3. Extract features**\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "holjmiWRS-RF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "0aa97464-8eb5-478a-e40b-42f1c2faf6ec"
      },
      "source": [
        "## --------------------------------------------------------\n",
        "# TODO - for each mouse, take only data that belongs to it :\n",
        "# note: not yet finished, for now use the data for all mice in X\n",
        "## --------------------------------------------------------\n",
        "\n",
        "## 1. example - for one mouse only:\n",
        "## ------------------------------\n",
        "# idx = 0\n",
        "# mouse_split_data = take_data_by_name(unique_name_list[idx], X, name_column)\n",
        "# print('mouse name:', unique_name_list[idx],', ' 'idx:', idx)\n",
        "# mouse_split_data\n",
        "\n",
        "## 2. trying for all mice:\n",
        "## ---------------------\n",
        "  # final data is made up of: \n",
        "    # avg. start freq. per syllable\n",
        "    # avg. end freq. per syllable\n",
        "    # avg. syllable duration per syllable\n",
        "    # syllable distribution - percentage of each syllable\n",
        "    # Bandwidth - TODO\n",
        "\n",
        "num_of_syllables = 10\n",
        "final_data_size = 4*num_of_syllables\n",
        "# initialize finalized data variable: mouse_final_data\n",
        "mouse_final_data = np.zeros([number_of_mice,final_data_size])\n",
        "\n",
        "\n",
        "for idx in range (33,36): #(number_of_mice):\n",
        "  mouse_split_data = take_data_by_name(unique_name_list[idx], X, name_column)\n",
        "  print('mouse name:', unique_name_list[idx],', ' 'idx:', idx)\n",
        "#  print('matching data:', '\\n',mouse_split_data)\n",
        "\n",
        "  # calculate feature 1 - average start freq for each syllable (Alon)\n",
        "  ## -------------------------------------------\n",
        "  print(\"\\n\", \"--- CALCULATING FEATURE 1: average start freq for each syllable ---\", \"\\n\")\n",
        "\n",
        "  # TODO \n",
        "  # extract all syllables per mouse - done\n",
        "  # create a dictionay with num of syllable as key and all it's start freqs arrange in list as a value\n",
        "  # for every value in the dictionary compute the average\n",
        "  # to it again in a loop for every mouse such that in the end I'll get an array with num of mouse as a key and the value is the dictionay with the average of start freqs per syllable (*think about better way to arrange the data)\n",
        "  \n",
        "\n",
        "  # create a dictionay with num of syllable as key and all it's start freqs arrange in list as a value\n",
        "  # dict = {}\n",
        "  # start_freq = np.array(mouse_split_data[\"Start Point (Hz)\"])\n",
        "  # syllable_num = np.array(mouse_split_data[\"Syllable number\"])\n",
        "  # start_freq_check_nan = [~np.isnan(start_freq)]\n",
        "  # count = 0\n",
        "  # for i in syllable_num:\n",
        "  #   j = [~np.isnan(i)]\n",
        "  #   if not j:\n",
        "  #     print(\"alon\")\n",
        "  #     continue\n",
        "  #   else:\n",
        "  #     dict[i] = dict[i] + start_freq[i]\n",
        "  # print(dict)\n",
        "  \n",
        "# print(start_freq)\n",
        "# print(len(start_freq))\n",
        "\n",
        "  \n",
        "  \n",
        "\n",
        "  # get the num of each syllable \n",
        "\n",
        "\n",
        "  # calculate feature 2 - average end freq for each syllable (Alon)\n",
        "  ## -------------------------------------------\n",
        "  print(\"\\n\", \"--- CALCULATING FEATURE 2: average end freq for each syllable ---\", \"\\n\")\n",
        "\n",
        "\n",
        "  # calculate feature 3 - syllable distribution (Itamar):\n",
        "  ## -------------------------------------------\n",
        "  print(\"\\n\", \"--- CALCULATING FEATURE 3: mouse's syllable distribution ---\", \"\\n\")\n",
        "# get rid of NaN\n",
        "  mouse_split_data = mouse_split_data.dropna(subset=[\"Syllable number\"])\n",
        "\n",
        "# take syll numbers\n",
        "  syllable_num_row = np.transpose(np.array(mouse_split_data[\"Syllable number\"]))\n",
        "  # print(syllable_num_row)\n",
        "\n",
        "# initialize distribution vector\n",
        "  distribution = np.zeros([1,10])\n",
        "  # print(distribution)\n",
        "\n",
        "# increment syllable count\n",
        "  for i in range(len(syllable_num_row)):\n",
        "    # print(\"iteration\", i)\n",
        "    syll = int(syllable_num_row[i])\n",
        "    # print(\"found syllable\", syll)\n",
        "    # print(\"old distribution:\", distribution)\n",
        "    distribution[0,syll-1] += 1 \n",
        "    # print(\"new distribution:\", distribution)\n",
        "\n",
        "# normalize histogram to distribution\n",
        "  distribution = distribution / distribution.sum()\n",
        "  print(\"final distribution:\", \"\\n\", distribution)\n",
        "\n",
        "# transfer results to mouse_final_data\n",
        "  mouse_final_data[idx,21:31] = distribution\n",
        "\n",
        "\n",
        "  # calculate feature 4 - average syllable duration for each syllable (Alon)\n",
        "  ## -------------------------------------------\n",
        "  print(\"\\n\", \"--- CALCULATING FEATURE 4: average syllable duration for each syllable ---\", \"\\n\")\n",
        "  ## HELP - convert \"Duration (s)\" to seconds\n",
        "  # from datetime import datetime, timedelta\n",
        "  # temp = X[\"Duration (s)\"]\n",
        "  # var = temp[20]\n",
        "  # # var = datetime.today()  \n",
        "  # print(var)\n",
        "  # print(type(var))\n",
        "  # another_temp = var.timestamp()\n",
        "  # print(another_temp)\n",
        "  # print(type(another_temp))\n",
        "  \n",
        "  \n",
        "  # HELP - group by syllable index, then take the mean of the duration column for each syllable\n",
        "  # NOTE - RIGHT NOW MIN AND MAX ARE POSSIBLE\n",
        "  mouse_duration = mouse_split_data[[\"Name\", \"Syllable number\",\"Duration (s)\"]]\n",
        "  a = mouse_duration.groupby('Syllable number', as_index=False)[\"Duration (s)\"].max()\n",
        "  print(\"for this mouse, each syllable's max duration is:\",\"\\n\", a)\n",
        "\n",
        "  \n",
        "  # calculate feature 5 - Bandwidth (???) - TODO\n",
        "  ## -------------------------------------------\n",
        "  print(\"\\n\", \"--- CALCULATING FEATURE 5: Bandwidth ---\", \"\\n\")\n",
        "\n",
        "  print(\"\\n\", \"--- FINISHED features, show final data: ---\", \"\\n\")\n",
        "  print(mouse_final_data[idx,:], \"\\n\")"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mouse name: 17472I , idx: 33\n",
            "\n",
            " --- CALCULATING FEATURE 1: average start freq for each syllable --- \n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-b53050e017c3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     54\u001b[0m       \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m       \u001b[0mdict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstart_freq\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: nan"
          ]
        }
      ]
    }
  ]
}