{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "audio_feature_extraction.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/etgins/Mice_ASD_Detection/blob/main/audio_feature_extraction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3YA25Z9BUZPM"
      },
      "source": [
        "----------------------------------------------\n",
        "Written by Itamar Ginsberg & Alon Schreuer, October 2021\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T4POWW7dSKd9"
      },
      "source": [
        "# **1. Import data and split labels**\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZGRoMFfM9O1p"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "# import dataset from xls\n",
        "import pandas as pd\n",
        "dataset = pd.read_excel('/content/drive/MyDrive/Project_A/Project_A/total_data UPDATED EM 020821.xlsx')\n",
        "dataset.to_csv (r'/content/drive/MyDrive/Project_A/Project_A/total_data UPDATED EM 020821.csv', index = None, header=True)\n",
        "dataset.dropna(axis = 0, how='any')\n",
        "\n",
        "# extract only the relevant columns / features\n",
        "X = dataset[[\"Name\", \"Start Point (Hz)\", \"End Point (Hz)\", \"Duration (s)\", \"Syllable number\"]]\n",
        "y = dataset[[\"Offspring Genotype\"]]\n",
        "\n",
        "# TODO - clean NaN values from dataset or X\n",
        "X.dropna(axis = 0, how='any')\n",
        "# X\n",
        "\n",
        "\n",
        "## TODO - encode text feature values\n",
        "# from sklearn.preprocessing import LabelEncoder\n",
        "# l1 = LabelEncoder()\n",
        "# l1.fit(X['Name'])\n",
        "# dataset.Name = l1.transform(dataset.Name)\n",
        "# dataset\n",
        "\n",
        "# X.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hz5Ehn_USzN5"
      },
      "source": [
        "# **2. Split data for different mice by name - unfinished**\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7nw3zPiKFS3M"
      },
      "source": [
        "# split dataset for each mouse\n",
        "\n",
        "def take_data_by_name(name_searched, Data, name_list):\n",
        "  # print(name_list)\n",
        "  ind = name_list == name_searched\n",
        "  # print(ind)\n",
        "  matching_data = Data[ind]\n",
        "  # print(matching_data)\n",
        "  return matching_data\n",
        "\n",
        "\n",
        "# find set of mouse names\n",
        "name_column = dataset[\"Name\"]\n",
        "unique_name_set = set(name_column)\n",
        "unique_name_list = list(unique_name_set)\n",
        "unique_name_list = unique_name_list[1:-1]   # first entry is column name\n",
        "number_of_mice = len(unique_name_list)\n",
        "\n",
        "## --------------------------------------------------------\n",
        "# TODO - for each mouse, take only data that belongs to it :\n",
        "# note: not yet finished, for now use the data for all mice in X\n",
        "## --------------------------------------------------------\n",
        "\n",
        "## 1. example - for one mouse only:\n",
        "## ------------------------------\n",
        "# idx = 1\n",
        "# mouse_split_data = take_data_by_name(unique_name_list[idx], X, name_column)\n",
        "# print('mouse name:', unique_name_list[idx],', ' 'idx:', idx)\n",
        "# mouse_split_data\n",
        "\n",
        "## 2. trying for all mice:\n",
        "## ---------------------\n",
        "\n",
        "# final data is made up of: \n",
        "  # avg. start freq. per syllable\n",
        "  # avg. end freq. per syllable\n",
        "  # avg. syllable duration per syllable\n",
        "  # syllable distribution - percentage of each syllable\n",
        "  # Bandwidth - TODO\n",
        "num_of_syllables = 10\n",
        "final_data_size = 4*num_of_syllables\n",
        " \n",
        "# initialize finalized data variable: mouse_final_data\n",
        "mouse_final_data = np.empty([number_of_mice,final_data_size])\n",
        "\n",
        "\n",
        "for idx in range (21,22): # (number_of_mice):\n",
        "  mouse_split_data = take_data_by_name(unique_name_list[idx], X, name_column)\n",
        "  print('mouse name:', unique_name_list[idx],', ' 'idx:', idx)\n",
        "  print('matching data:', '\\n',mouse_split_data)\n",
        "\n",
        "## --------------------------------------------------------"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6eQ4bDtlTEnT"
      },
      "source": [
        "# **3. Extract features**\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "holjmiWRS-RF"
      },
      "source": [
        "  # calculate feature 1 - average start freq for each syllable (Alon)\n",
        "  ## -------------------------------------------\n",
        "\n",
        "  # calculate feature 2 - average end freq for each syllable (Alon)\n",
        "  ## -------------------------------------------\n",
        "\n",
        "  # calculate feature 3 - syllable distribution (Itamar):\n",
        "  ## -------------------------------------------\n",
        "  # df['color_pro'] = df.groupby('color')['color'].transform('count')\n",
        "  # df['color_pro'] = df['color_pro'].map(lambda x : x/len(df))\n",
        "  mouse_split_data['syllable_distribution'] = mouse_split_data.groupby('Syllable number')['Syllable number'].transform('count')\n",
        "    \n",
        "  # calculate feature 4 - average syllable duration for each syllable (Alon)\n",
        "  ## -------------------------------------------\n",
        "\n",
        "  # calculate feature 5 - Bandwidth (???) - TODO\n",
        "  ## -------------------------------------------\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}