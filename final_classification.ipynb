{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "final_classification.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNnyRSKcARWk2fFDwFuFCs0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/etgins/Mice_ASD_Detection/blob/main/final_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dpc8qmsMKteD"
      },
      "source": [
        "----------------------------------------------\n",
        "Written by Itamar Ginsberg & Alon Schreuer, October 2021\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9tnwBquhK7HB"
      },
      "source": [
        "# TODO - choose workframe - SKlearn or ???\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_sFR434NKpxa"
      },
      "source": [
        "import time\n",
        "from xgboost import XGBClassifier\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "# import xgboost as xgb\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
        "from sklearn.linear_model import Ridge, Lasso\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nNDYm3AAgK1z"
      },
      "source": [
        "# load data from xls/csv file"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eo9dlYuAgQzC"
      },
      "source": [
        "# pre-process data\n",
        "  # normalize - different magnitudes between features\n",
        "    # min-max (?)\n",
        "  # create augmentations (?)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TA4AOodEgbI0"
      },
      "source": [
        "# train-val-test split data (80-10-10 (?) )\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1)\n",
        "X_train, X_validation, y_train, y_validation = train_test_split(X_train, y_train, test_size=(1/9))\n",
        "\n",
        "# transform data to DMatrix - a format XGboost can handle well\n",
        "D_train = xgb.DMatrix(X_train, label=Y_train)\n",
        "D_test = xgb.DMatrix(X_test, label=Y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GMSb94CuMAoS"
      },
      "source": [
        "# define model hyper-parameters\n",
        "\n",
        "param = {\n",
        "    'eta': 0.3, # learning rate - reduce weight of new models, prevent overfitting\n",
        "    'max_depth': 3,  # max_depth of tree\n",
        "    'objective': 'multi:softprob',  # loss function\n",
        "    'num_class': 2} # number of classes\n",
        "\n",
        "steps = 20  # The number of training iterations"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b4MC-q7INeAB"
      },
      "source": [
        "XGBoost:\n",
        "------------\n",
        "1. https://towardsdatascience.com/running-xgboost-on-google-colab-free-gpu-a-case-study-841c90fef101\n",
        "2. https://towardsdatascience.com/ensemble-learning-and-model-interpretability-a-case-study-95141d75a96c\n",
        "3. https://towardsdatascience.com/https-medium-com-vishalmorde-xgboost-algorithm-long-she-may-rein-edd9f99be63d\n",
        "4. https://towardsdatascience.com/a-beginners-guide-to-xgboost-87f5d4c30ed7\n",
        "5. https://towardsdatascience.com/a-journey-through-xgboost-milestone-2-f3410109be5a\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aix8F7yZgqMU"
      },
      "source": [
        "# create/load model\n",
        "\n",
        "seed = 1\n",
        "model = XGBClassifier(n_estimators=500, random_state=seed)\n",
        "# define the eval set and metric\n",
        "eval_set = [(X_train, y_train), (X_test, y_test)]\n",
        "eval_metric = [\"auc\",\"error\"]\n",
        "\n",
        "# choose regularization (?)\n",
        "\n",
        "# fit the model\n",
        "%time \n",
        "model.fit(X_train, y_train, eval_metric=eval_metric, eval_set=eval_set, verbose=False)\n",
        "\n",
        "# final model assessment\n",
        "pred_test = model.predict(X_test)\n",
        "pred_train = model.predict(X_train)\n",
        "print('Train Accuracy: ', accuracy_score(y_train, pred_train))\n",
        "print('Test Accuraccy: ', accuracy_score(y_test, pred_test))\n",
        "print('Classification Report:')\n",
        "print(classification_report(y_test,pred_test))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YDPC7DoigXlp"
      },
      "source": [
        "# train model\n",
        "  # use batching"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PnQcY0kKOgj0"
      },
      "source": [
        "# create a readable description of the model\n",
        "model.dump_model('dump.raw.txt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AbKp7s4wgZEI"
      },
      "source": [
        "# test model"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}